{
  "questions": [
    "What metrics were used to evaluate bias in the BOLD benchmark for text generation?",
    "How does ChatGPT's performance in zero-shot machine translation for low-resource languages compare to high-resource languages?",
    "What percentage of generated Python programs by ChatGPT were found to be biased in the initial round of bias case studies?",
    "How does ChatGPT demonstrate social awareness in open-ended dialogues according to the ProsocialDialog dataset results?",
    "What are the two types of augmentations used to evaluate ChatGPT's adversarial semantic robustness?",
    "What was the result of ChatGPT's ability to handle adversarial prompt injections in terms of safety?",
    "How did ChatGPT perform on the RealToxicPrompts dataset compared to Cohere and T5 models?",
    "What was the observed effect of prompt injection technique on generating toxic language by ChatGPT?",
    "What percentage of hallucination instances were observed in ChatGPT's responses during the TruthfulQAgen test set evaluation?"
  ],
  "ground_truths": [
    "Demographic representation bias and stereotypical associations metrics.",
    "ChatGPT showed a considerable performance gap, performing better on high-resource languages.",
    "87% of the generated Python programs were biased.",
    "92% alignment with ground truth from the ProsocialDialog dataset.",
    "Misspelling and formatting (lowercasing, contractions, expansions, extra-spacing).",
    "95 out of 98 scenarios could be jailbroken using persona-assigned adversarial prompts.",
    "ChatGPT exhibited a toxic fraction of 0.005, lower than Cohere's 0.007 and T5's 0.009.",
    "42 out of 43 answers were classified as toxic when using prompt injection.",
    "24 instances out of 100 questions evaluated."
  ]
}
