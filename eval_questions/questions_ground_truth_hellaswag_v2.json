{
  "questions": [
    "What is the main objective of the HellaSwag dataset?",
    "What methodology is used to create challenging datasets for language models in HellaSwag?",
    "How does the accuracy of human performance compare to state-of-the-art models on the HellaSwag dataset?",
    "What are the two primary sources of context used in the HellaSwag dataset?",
    "How does the HellaSwag dataset challenge the limitations of BERT and GPT models?",
    "What is the role of Adversarial Filtering in the creation of HellaSwag?",
    "How do the lengths of WikiHow and ActivityNet contexts in HellaSwag affect model performance?",
    "What distinguishes the zero-shot and in-domain evaluation categories in HellaSwag?",
    "How does the performance of models on HellaSwag indicate the need for future NLP model improvements?"
  ],
  "ground_truths": [
    "To challenge state-of-the-art models with commonsense reasoning tasks that are easy for humans but difficult for machines.",
    "Adversarial Filtering (AF) is used, which involves selecting challenging machine-generated wrong answers through a series of discriminators.",
    "Humans achieve around 95% accuracy, whereas state-of-the-art models struggle with accuracies significantly below 50%.",
    "Video captions from ActivityNet and how-to articles from WikiHow.",
    "The dataset reveals that these models, while performing well on many NLP tasks, still struggle with complex commonsense reasoning and context understanding.",
    "AF iteratively selects an adversarial set of wrong answers that are challenging for models but easy for humans, making the dataset robust against machine learning models.",
    "Longer contexts in WikiHow provide more opportunities for detectable mistakes, challenging models more effectively than the shorter ActivityNet captions.",
    "Zero-shot evaluation categories contain examples from unseen categories, testing the model's ability to generalize, while in-domain categories are seen during training.",
    "The significant gap between human and model performance on HellaSwag highlights the necessity for advancements in model capabilities, especially in commonsense reasoning."
  ]
}
