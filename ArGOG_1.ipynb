{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook to duplicate ARGOG using cells \n",
    "## code is from main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing stuff\n",
    "import openai\n",
    "import chromadb\n",
    "import pandas as pd\n",
    "from utils import run_experiment, load_config\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import VectorStoreIndex, PromptTemplate, ServiceContext, Settings\n",
    "# from llama_index.settings import Settings\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "from llama_index.core.indices.query.query_transform import HyDEQueryTransform\n",
    "from llama_index.core.query_engine import TransformQueryEngine, RetrieverQueryEngine\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core.postprocessor import LLMRerank\n",
    "from llama_index.core.retrievers import QueryFusionRetriever\n",
    "from tonic_validate import ValidateScorer, ValidateApi\n",
    "from tonic_validate.metrics import RetrievalPrecisionMetric, AnswerSimilarityMetric\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SETUP --------------------------------------------------------------------------------------------------------------\n",
    "# Load the config file (.env vars)\n",
    "load_config()\n",
    "\n",
    "# Set the OpenAI API key for authentication.\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "tonic_validate_api_key = os.getenv(\"TONIC_VALIDATE_API_KEY\")\n",
    "tonic_validate_project_key = os.getenv(\"TONIC_VALIDATE_PROJECT_KEY\")\n",
    "tonic_validate_benchmark_key = os.getenv(\"TONIC_VALIDATE_BENCHMARK_KEY\")\n",
    "validate_api = ValidateApi(tonic_validate_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service context\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-large\")\n",
    "# service_context = ServiceContext.from_defaults(llm = llm, embed_model = embed_model)\n",
    "# settings = Settings(llm=llm, embed_model=embed_model)\n",
    "Settings.llm = llm \n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # existing_collections = chroma_client.list_collections()\n",
    "# # print(existing_collections)\n",
    "# # First, check if collection exists and create it if it doesn't\n",
    "# try:\n",
    "#     chroma_collection = chroma_client.get_collection(\"ai_arxiv_full\")\n",
    "# except:\n",
    "#     # Create new collection\n",
    "#     chroma_collection = chroma_client.create_collection(\n",
    "#         name=\"ai_arxiv_full\",\n",
    "#         metadata={\"description\": \"ArXiv AI papers collection\"}\n",
    "#     )\n",
    "\n",
    "# # Now you can use the collection\n",
    "# vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "# index = VectorStoreIndex.from_vector_store(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings, StorageContext, VectorStoreIndex\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser  # Updated import path\n",
    "\n",
    "# Create the collection first\n",
    "try:\n",
    "    chroma_collection_sentence_window = chroma_client.get_collection(\"ai_arxiv_sentence_window\")\n",
    "except:\n",
    "    chroma_collection_sentence_window = chroma_client.create_collection(\n",
    "        name=\"ai_arxiv_sentence_window\",\n",
    "        metadata={\"description\": \"ArXiv AI papers with sentence window processing\"}\n",
    "    )\n",
    "\n",
    "# Set up sentence window processing\n",
    "node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=3,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\"\n",
    ")\n",
    "\n",
    "# Update settings with the node parser\n",
    "Settings.node_parser = node_parser\n",
    "\n",
    "# Set up vector store and index\n",
    "vector_store_sentence_window = ChromaVectorStore(\n",
    "    chroma_collection=chroma_collection_sentence_window\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=vector_store_sentence_window\n",
    ")\n",
    "\n",
    "# Create the index\n",
    "index_sentence_window = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store_sentence_window\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional VDB\n",
    "chroma_collection = chroma_client.get_collection(\"ai_arxiv_full\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "index = VectorStoreIndex.from_vector_store(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentence window VDB\n",
    "chroma_collection_sentence_window = chroma_client.get_collection(\"ai_arxiv_sentence_window\")\n",
    "vector_store_sentence_window = ChromaVectorStore(chroma_collection=chroma_collection_sentence_window)\n",
    "index_sentence_window = VectorStoreIndex.from_vector_store(vector_store=vector_store_sentence_window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document summary VDB\n",
    "from llama_index.core import load_index_from_storage\n",
    "from llama_index.core import StorageContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'e:/Dropbox/GithubRepo/StanfordContinuingStudies/TECH14LLMProduction/ARAGOG/ai_arxiv_doc_summary/docstore.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# storage_context = StorageContext.from_defaults(persist_dir=\"Obelix\")\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m storage_context \u001b[38;5;241m=\u001b[39m StorageContext\u001b[38;5;241m.\u001b[39mfrom_defaults(persist_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mai_arxiv_doc_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m doc_summary_index \u001b[38;5;241m=\u001b[39m load_index_from_storage(llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[0;32m      4\u001b[0m                                               storage_context\u001b[38;5;241m=\u001b[39mstorage_context,\n\u001b[0;32m      5\u001b[0m                                              embed_model \u001b[38;5;241m=\u001b[39m embed_model)\n",
      "File \u001b[1;32mc:\\Users\\Tiger\\anaconda3\\envs\\ARAGOG\\Lib\\site-packages\\llama_index\\core\\storage\\storage_context.py:111\u001b[0m, in \u001b[0;36mStorageContext.from_defaults\u001b[1;34m(cls, docstore, index_store, vector_store, image_store, vector_stores, graph_store, property_graph_store, persist_dir, fs)\u001b[0m\n\u001b[0;32m    109\u001b[0m         vector_stores[IMAGE_VECTOR_STORE_NAMESPACE] \u001b[38;5;241m=\u001b[39m image_store\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m     docstore \u001b[38;5;241m=\u001b[39m docstore \u001b[38;5;129;01mor\u001b[39;00m SimpleDocumentStore\u001b[38;5;241m.\u001b[39mfrom_persist_dir(\n\u001b[0;32m    112\u001b[0m         persist_dir, fs\u001b[38;5;241m=\u001b[39mfs\n\u001b[0;32m    113\u001b[0m     )\n\u001b[0;32m    114\u001b[0m     index_store \u001b[38;5;241m=\u001b[39m index_store \u001b[38;5;129;01mor\u001b[39;00m SimpleIndexStore\u001b[38;5;241m.\u001b[39mfrom_persist_dir(\n\u001b[0;32m    115\u001b[0m         persist_dir, fs\u001b[38;5;241m=\u001b[39mfs\n\u001b[0;32m    116\u001b[0m     )\n\u001b[0;32m    117\u001b[0m     graph_store \u001b[38;5;241m=\u001b[39m graph_store \u001b[38;5;129;01mor\u001b[39;00m SimpleGraphStore\u001b[38;5;241m.\u001b[39mfrom_persist_dir(\n\u001b[0;32m    118\u001b[0m         persist_dir, fs\u001b[38;5;241m=\u001b[39mfs\n\u001b[0;32m    119\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Tiger\\anaconda3\\envs\\ARAGOG\\Lib\\site-packages\\llama_index\\core\\storage\\docstore\\simple_docstore.py:57\u001b[0m, in \u001b[0;36mSimpleDocumentStore.from_persist_dir\u001b[1;34m(cls, persist_dir, namespace, fs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m     persist_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(persist_dir, DEFAULT_PERSIST_FNAME)\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_persist_path(persist_path, namespace\u001b[38;5;241m=\u001b[39mnamespace, fs\u001b[38;5;241m=\u001b[39mfs)\n",
      "File \u001b[1;32mc:\\Users\\Tiger\\anaconda3\\envs\\ARAGOG\\Lib\\site-packages\\llama_index\\core\\storage\\docstore\\simple_docstore.py:74\u001b[0m, in \u001b[0;36mSimpleDocumentStore.from_persist_path\u001b[1;34m(cls, persist_path, namespace, fs)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_persist_path\u001b[39m(\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     fs: Optional[fsspec\u001b[38;5;241m.\u001b[39mAbstractFileSystem] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     65\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimpleDocumentStore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     66\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create a SimpleDocumentStore from a persist path.\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \n\u001b[0;32m     68\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     72\u001b[0m \n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m     simple_kvstore \u001b[38;5;241m=\u001b[39m SimpleKVStore\u001b[38;5;241m.\u001b[39mfrom_persist_path(persist_path, fs\u001b[38;5;241m=\u001b[39mfs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(simple_kvstore, namespace)\n",
      "File \u001b[1;32mc:\\Users\\Tiger\\anaconda3\\envs\\ARAGOG\\Lib\\site-packages\\llama_index\\core\\storage\\kvstore\\simple_kvstore.py:97\u001b[0m, in \u001b[0;36mSimpleKVStore.from_persist_path\u001b[1;34m(cls, persist_path, fs)\u001b[0m\n\u001b[0;32m     95\u001b[0m fs \u001b[38;5;241m=\u001b[39m fs \u001b[38;5;129;01mor\u001b[39;00m fsspec\u001b[38;5;241m.\u001b[39mfilesystem(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     96\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpersist_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mopen(persist_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     98\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(data)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\fsspec\\spec.py:1303\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[1;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[0;32m   1301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1302\u001b[0m     ac \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautocommit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intrans)\n\u001b[1;32m-> 1303\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(\n\u001b[0;32m   1304\u001b[0m         path,\n\u001b[0;32m   1305\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   1306\u001b[0m         block_size\u001b[38;5;241m=\u001b[39mblock_size,\n\u001b[0;32m   1307\u001b[0m         autocommit\u001b[38;5;241m=\u001b[39mac,\n\u001b[0;32m   1308\u001b[0m         cache_options\u001b[38;5;241m=\u001b[39mcache_options,\n\u001b[0;32m   1309\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1310\u001b[0m     )\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1312\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compr\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\fsspec\\implementations\\local.py:191\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[1;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_mkdir \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent(path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LocalFileOpener(path, mode, fs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\fsspec\\implementations\\local.py:355\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[1;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression \u001b[38;5;241m=\u001b[39m get_compression(path, compression)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[1;32m--> 355\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\fsspec\\implementations\\local.py:360\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocommit \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m--> 360\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    361\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression:\n\u001b[0;32m    362\u001b[0m             compress \u001b[38;5;241m=\u001b[39m compr[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression]\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'e:/Dropbox/GithubRepo/StanfordContinuingStudies/TECH14LLMProduction/ARAGOG/ai_arxiv_doc_summary/docstore.json'"
     ]
    }
   ],
   "source": [
    "# storage_context = StorageContext.from_defaults(persist_dir=\"Obelix\")\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"ai_arxiv_doc_summary\")\n",
    "doc_summary_index = load_index_from_storage(llm=llm,\n",
    "                                              storage_context=storage_context,\n",
    "                                             embed_model = embed_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ARAGOG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
